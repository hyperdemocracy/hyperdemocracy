{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is a slightly modified version of a script written for the hyperdemocracy 2023-06 workshop session.\n",
    "This notebook grabs a huggingface dataset containing info on U.S Congress bills, does some inspection and processing,\n",
    "and creates a simple grpah using the networkx module\n",
    "'''\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import openai\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_assembly_records(\n",
    "    ds_name=\"hyperdemocracy/us-congress-bills\",\n",
    "    process=True, \n",
    "    strip_html=True, \n",
    "    remove_empty_body=True,\n",
    "    col_order=None\n",
    ") -> pd.DataFrame: \n",
    "    '''\n",
    "    Function to load huggingface dataset from huggingface, specifically, the senate data\n",
    "    '''\n",
    "    ds = load_dataset(ds_name, split=\"train\") # Load the train split of from hyperdemocracy dataset\n",
    "    df = ds.to_pandas() # convert to pd dataframe\n",
    "    if process: \n",
    "        df['congress_num'] = None   # Init new columns\n",
    "        df['legis_class'] = None\n",
    "        df['legis_num'] = None\n",
    "        for irow, row in df.iterrows():\n",
    "             # For each dataset row, extract 3 info from key column, and populate the new columns\n",
    "            congress_num, legis_class, legis_num = split_key(row['id'])\n",
    "            df.loc[irow, 'congress_num'] = congress_num\n",
    "            df.loc[irow, 'legis_class'] = legis_class\n",
    "            df.loc[irow, 'legis_num'] = legis_num\n",
    "\n",
    "    if remove_empty_body: \n",
    "        # ??!?\n",
    "        df = df[df['text']!='']\n",
    "        df = df[df['summary_text']!='']\n",
    "\n",
    "    if strip_html: \n",
    "        # Extract all text from bills with BeautifulSoup module\n",
    "\n",
    "        # The bill's text is already in the \"text\" column\n",
    "        # df['body'] = df['body'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "        df['summary_text'] = df['summary_text'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "\n",
    "        # Already have congress gov url\n",
    "        # df['congress_gov_url'] = df['key'].apply(url_from_key)\n",
    "\n",
    "    \"\"\"reorder columns based on a list of column names in passed order\"\"\"\n",
    "    if col_order is not None: \n",
    "        colset = set(df.columns.tolist())\n",
    "        ordered = []\n",
    "        for col in col_order: \n",
    "            if col not in colset: \n",
    "                raise ValueError(f\"Column {col} not in dataframe.\")\n",
    "            else: \n",
    "                ordered.append(col)\n",
    "                colset.remove(col)\n",
    "        ordered += list(colset)\n",
    "        df = df[ordered]\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def url_from_key(key): \n",
    "    \"\"\"Return congress.gov url from key.\"\"\"\n",
    "    # TODO add assembled url builder option here as well\n",
    "    url_map = {\n",
    "        \"HR\": \"house-bill\",\n",
    "        \"HCONRES\": \"house-concurrent-resolution\",\n",
    "        \"HRES\": \"house-resolution\",\n",
    "        \"HJRES\": \"house-joint-resolution\",\n",
    "        \"S\": \"senate-bill\",\n",
    "        \"SCONRES\": \"senate-concurrent-resolution\",\n",
    "        \"SRES\": \"senate-resolution\",\n",
    "        \"SJRES\": \"senate-joint-resolution\",\n",
    "    }\n",
    "    congress_num, legis_class, legis_num = split_key(key)\n",
    "    url_legis_class = url_map[legis_class]\n",
    "    url = f\"https://www.congress.gov/bill/{congress_num}th-congress/{url_legis_class}/{legis_num}\"\n",
    "    return url\n",
    "\n",
    "def split_key(key):\n",
    "    \"\"\"\n",
    "    TODO: add a link explaining this notation and variable names\n",
    "    \"\"\"\n",
    "    congress_num, legis_class, legis_num = re.match(\"(\\d+)(\\D+)(\\d+)\", key).groups()\n",
    "    return congress_num, legis_class, legis_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name=\"hyperdemocracy/us-congress-bills\"\n",
    "ds = load_dataset(ds_name, split=\"train\") # Load the train split of from hyperdemocracy dataset\n",
    "df = ds.to_pandas() # convert to pd dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quan Minh Pham\\AppData\\Local\\Temp\\ipykernel_25516\\3553170585.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_types = df.applymap(type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id [<class 'str'>]\n",
      "title [<class 'str'>]\n",
      "congress [<class 'int'>]\n",
      "type [<class 'str'>]\n",
      "number [<class 'int'>]\n",
      "origin_chamber [<class 'str'>]\n",
      "sponsors [<class 'numpy.ndarray'>]\n",
      "cosponsors [<class 'numpy.ndarray'>]\n",
      "congress_gov_url [<class 'str'>]\n",
      "govtrack_url [<class 'str'>]\n",
      "summary_text [<class 'str'> <class 'NoneType'>]\n",
      "summary_meta [<class 'dict'> <class 'NoneType'>]\n",
      "subjects [<class 'numpy.ndarray'>]\n",
      "policy_area [<class 'str'> <class 'NoneType'>]\n",
      "bill [<class 'dict'>]\n",
      "metadata_xml [<class 'str'>]\n",
      "text_type [<class 'str'> <class 'NoneType'>]\n",
      "text_date [<class 'str'> <class 'NoneType'>]\n",
      "text_url [<class 'str'> <class 'NoneType'>]\n",
      "text_xml [<class 'str'> <class 'NoneType'>]\n",
      "text [<class 'str'> <class 'NoneType'>]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "First, obtain a dataframe containing all entries, where at least one column value is not what it is suppose to be\n",
    "To know this, we wanna see if any columns contain more than one datatype\n",
    "'''\n",
    "\n",
    "df_types = df.applymap(type)\n",
    "for c in df_types.columns:\n",
    "    print(c, df_types[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of bills without summaries: 5268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19      2023-03-23T04:00:00+00:00\n",
       "21      2023-03-28T04:00:00+00:00\n",
       "24      2023-03-30T04:00:00+00:00\n",
       "26      2023-04-13T04:00:00+00:00\n",
       "27      2023-04-25T04:00:00+00:00\n",
       "                  ...            \n",
       "9267    2023-09-07T04:00:00+00:00\n",
       "9268    2023-09-07T04:00:00+00:00\n",
       "9328    2023-03-01T05:00:00+00:00\n",
       "9333    2023-03-02T05:00:00+00:00\n",
       "9336    2023-03-07T05:00:00+00:00\n",
       "Name: text_date, Length: 5268, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "From output above, we know summary, policy area, text type and other stuff may be empty\n",
    "Now to do some inspecting, looking at entries with None in them\n",
    "\n",
    "From output below, we know a majority of bills don't have a summary. They do however, have text available\n",
    "'''\n",
    "\n",
    "df_none_summary_text = df[df['summary_text'].apply(type) == type(None)]\n",
    "# print(df_none_summary_text.head())\n",
    "print(\"No. of bills without summaries: \" + str(len(df_none_summary_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bills without text: 71\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Checking bills without texts shows that 71 bills don't have their text scanned yet. At least, that's the assumption as to why \n",
    "the text fields of these bills are empty. Without text, naturally, there is no summary for these bills\n",
    "'''\n",
    "\n",
    "\n",
    "df_no_text = df[df['text_type'].apply(type) == type(None)]\n",
    "print(\"Number of bills without text: \" + str(len(df_no_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Quan Minh Pham\\Documents\\MY STUFF\\Projects\\HacDC\\hyperdemocracy-workshop-2023-06\\test_data.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Quan%20Minh%20Pham/Documents/MY%20STUFF/Projects/HacDC/hyperdemocracy-workshop-2023-06/test_data.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Quan%20Minh%20Pham/Documents/MY%20STUFF/Projects/HacDC/hyperdemocracy-workshop-2023-06/test_data.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mDo dataframe processing, same as in the py notebook\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Quan%20Minh%20Pham/Documents/MY%20STUFF/Projects/HacDC/hyperdemocracy-workshop-2023-06/test_data.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Quan%20Minh%20Pham/Documents/MY%20STUFF/Projects/HacDC/hyperdemocracy-workshop-2023-06/test_data.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcongress_num\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m   \u001b[39m# Init new columns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Quan%20Minh%20Pham/Documents/MY%20STUFF/Projects/HacDC/hyperdemocracy-workshop-2023-06/test_data.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlegis_class\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Quan%20Minh%20Pham/Documents/MY%20STUFF/Projects/HacDC/hyperdemocracy-workshop-2023-06/test_data.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlegis_num\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Do dataframe processing, same as in the py notebook\n",
    "'''\n",
    "\n",
    "df['congress_num'] = None   # Init new columns\n",
    "df['legis_class'] = None\n",
    "df['legis_num'] = None\n",
    "\n",
    "for irow, row in df.iterrows():\n",
    "    # For each dataset row, extract 3 info from key column, and populate the new columns\n",
    "    congress_num, legis_class, legis_num = split_key(row['id'])\n",
    "    df.loc[irow, 'congress_num'] = congress_num\n",
    "    df.loc[irow, 'legis_class'] = legis_class\n",
    "    df.loc[irow, 'legis_num'] = legis_num\n",
    "\n",
    "# Filter all bills without summaries and text\n",
    "df = df[df['text_type'].apply(type) != type(None)]\n",
    "df = df[df['summary_text'].apply(type) != type(None)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Make a graph containing nodes which are bills without summaries and sponsors\n",
    "'''\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, record in df.iterrows():\n",
    "    node = (record['id'], {\"kind\": \"record\", \"name\": record[\"title\"]})  # Adding Record (Bill) nodes\n",
    "    G.add_nodes_from([node])\n",
    "    # Make sponsor nodes\n",
    "    for sponsor in record['sponsors']:\n",
    "        # For each bill, add sponsor nodes\n",
    "        node = (sponsor['bioguideId'], {\"name_tag\": sponsor['fullName'], \"kind\": \"person\"})\n",
    "        G.add_nodes_from([node])\n",
    "        edge = (record['id'], sponsor['bioguideId'], {\"kind\": 'sponsor'})\n",
    "        G.add_edges_from([edge])\n",
    "\n",
    "    # Make cosponsor nodes TODO\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
